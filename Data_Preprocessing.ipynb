{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1178c7d5",
   "metadata": {},
   "source": [
    "# Pre-Processing: Vom Text zu Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf625cbd",
   "metadata": {},
   "source": [
    "## Ablauf...\n",
    "\n",
    "* [Run code](#1-bullet)\n",
    "* [Tabelle mit Texten importieren](#2-bullet)\n",
    "* [Den Text \"reinigen\" und Stop-Wörter entfernen](#3-bullet)\n",
    "* [Lemmatisierung von Wörtern](#4-bullet)\n",
    "* [Part of Speech Tagging](#5-bullet)\n",
    "* [Named Entities Recognition](6#-bullet)\n",
    "* [Gewünschten Text exportieren](#7-bullet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc8fc5c",
   "metadata": {},
   "source": [
    "## Run code <a class=\"anchor\" id=\"1-bullet\"></a>\n",
    "\n",
    "Um Code in *Jupyter Notebooks* auszühren, müssen Sie auf **Run** klicken, das sich in der oberen Leiste finden. Klicken Sie dafür zunächst auf das Feld, das Sie ausführen möchten und anschließend auf **Run**. Sie können auch 'Shift' und 'Enter' verwenden. Wird das Feld gerade ausgeführt, erscheint links im Kästchen ein Sternchen. Dies bedeutet, dass das Programm gerade arbeitet. Wurde das Feld erfolgreich ausgeführt, erscheint eine Nummer im selben Kästchen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba3ea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#languange processing imports\n",
    "import gensim, spacy, logging, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import sys\n",
    "import re, numpy as np, pandas as pd\n",
    "from pprint import pprint\n",
    "import spacy\n",
    "from openpyxl import Workbook\n",
    "\n",
    "#For the text overview\n",
    "from nltk import FreqDist\n",
    "\n",
    "#Word Cloud and Visualization\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799ce53b",
   "metadata": {},
   "source": [
    "## Tabelle mit Texten importieren <a class=\"anchor\" id=\"2-bullet\"></a>\n",
    "\n",
    "Hier sehen Sie die importierte Excel-Tabelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e0aa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(('Data/uebungstexte_notebook.xlsx'), engine='openpyxl',) \n",
    "df.style.set_caption('Excel Tabelle').hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a67f077",
   "metadata": {},
   "source": [
    "## Den Text \"reinigen\" und Stop-Wörter entfernen <a class=\"anchor\" id=\"3-bullet\"></a>\n",
    "\n",
    "Nun wird der Text gereinigt, das heißt, es werden Satzzeichen entfernt, alle Wörter werden einheitlich klein geschrieben und Stop-Wörter werden entfernt. Stop-Wörter sind Wörter, die häufig vorkommen und haben für gewöhnlich keine Relevanz für weitere Analysen. Hierzu gehören Wörter wie \"und\", \"auf\", \"mit\" usw. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c143851",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Functions to clean, tokenize, and stem the data\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def initial_clean(text):\n",
    "    text = re.sub(r'[^\\w\\s]','',text)\n",
    "    text = text.lower() \n",
    "    text = nltk.word_tokenize(text)\n",
    "    return text\n",
    "\n",
    "stop_words = stopwords.words('german')#change the language here\n",
    "\n",
    "stop_words.extend([]) #add additional words here\n",
    "def remove_stop_words(text):\n",
    "    return [word for word in text if word not in stop_words]\n",
    "\n",
    "def apply_all(text):\n",
    "    return remove_stop_words(initial_clean(text))\n",
    "df['tokenized'] = df['text'].apply(apply_all) \n",
    "df.style.set_caption('Text und Tokens').hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f61d5d9",
   "metadata": {},
   "source": [
    "## Lemmatisierung von Wörtern <a class=\"anchor\" id=\"4-bullet\"></a>\n",
    "Die lexikographische Reduktion der Flexionsformen eines Wortes auf eine Grundform, also die Festlegung der Grundform eines Lexems und die Anordnung der Lemmata wird auch Lemmatisierung genannt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99940735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "def lemmatization(texts):\n",
    "    texts_out = []\n",
    "    nlp = spacy.load('de_core_news_sm')\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc])   \n",
    "    return texts_out\n",
    "\n",
    "df['lemmatized'] = lemmatization(df['tokenized'])\n",
    "df.style.set_caption('Text, tokens und lemmas').hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf4637e",
   "metadata": {},
   "source": [
    "## Part of Speech Tagging <a class=\"anchor\" id=\"5-bullet\"></a>\n",
    "\n",
    "Unter **Part-of-speech-Tagging** (POS-Tagging) versteht man die Zuordnung von Wörtern und Satzzeichen eines Textes zu Wortarten (englisch part of speech). Hierzu wird sowohl die Definition des Wortes als auch der Kontext (z. B. angrenzende Adjektive oder Nomen) berücksichtigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cac143a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tagging(texts, allowed_postags=['NOUN']): # possible tags'NOUN', 'ADJ', 'ADV', 'VERB'\n",
    "    texts_out = []\n",
    "    nlp = spacy.load('de_core_news_sm')\n",
    "    for sent in texts:\n",
    "        doc = nlp(sent) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])   \n",
    "    return texts_out\n",
    "\n",
    "df['tagging'] = tagging(df['text'])\n",
    "df.style.set_caption('Only nouns').hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3641f8b6",
   "metadata": {},
   "source": [
    "## Named Entities Recognition <a class=\"anchor\" id=\"6-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858caed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "for i in range(len(df)) : \n",
    "    df.iloc[i,6] = ' '.join(df.iloc[i,6])\n",
    "NER = spacy.load('de_core_news_sm')\n",
    "data_ready2 = NER(df['lemmatized'][0])\n",
    "text = displacy.render(data_ready2,style=\"ent\",jupyter=True)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6b0d51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('de_core_news_sm')\n",
    "list_ = df.groupby('lemmatized').apply(list)\n",
    "doc = nlp(str(list_)) \n",
    "loc = [] \n",
    "for ent in doc.ents:\n",
    "    if (ent.label_ == 'LOC'):\n",
    "            loc.append(ent.text)\n",
    "    freq = {}       \n",
    "    for item in loc:\n",
    "        if (item in freq):\n",
    "            freq[item] += 1\n",
    "        else:\n",
    "            freq[item] = 1\n",
    "loc = []\n",
    "number = []\n",
    "for key, value in freq.items():\n",
    "    loc.append(key)\n",
    "    number.append(value)\n",
    "df_loc = pd.DataFrame(np.column_stack([loc]), \n",
    "                                columns=['Ort'])\n",
    "df_number = pd.DataFrame(np.column_stack([number]), \n",
    "                                columns=['Anzahl']) \n",
    "df_ne = pd.concat([df_loc, df_number],axis=1)\n",
    "df_ne.columns=['Ort', 'Anzahl']\n",
    "df_ne.to_excel('locations.xlsx')\n",
    "df_ne.style.set_caption('Named Entities_Locations').hide_index() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c54c6c",
   "metadata": {},
   "source": [
    "## Gewünschten Text exportieren <a class=\"anchor\" id=\"7-bullet\"></a>\n",
    "\n",
    "Am Ende können Sie die gewünschten Resultate in Form der Excel Tabelle exportieren. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee5a411",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(df)) :\n",
    "    df.iloc[i,6] = ' '.join(df.iloc[i,6])\n",
    "deselectlist =[ 'tokenized', 'tagging']\n",
    "selectlist =[x for x in df.columns if x not in deselectlist]\n",
    "df = df[selectlist]\n",
    "    \n",
    "df.to_excel('results.xlsx')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
